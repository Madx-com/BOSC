# Teori
## Pthreads
Pthread er et standardiseret trådbibliotek som bruges til at oprette tråde sådan at man kan køre funktioner parrallelt, samle resultater fra barne tråde til forældretråden, og destruere tråde som blev skabt når man er færdig med at bruge dem.
 
## Mutex
Mutex bruges når man har kritiske sectioner i sin kode og vil synkronisere sine processertråde. Hvis flere tråde bruger en værdi i den kritiske section, og ændre på den parrallelt, vides det ikke hvornår trådene ændre på værdien, dette kan skabe problemer og give forkerte læsninger også kaldet dirty reads. Ved brug af mutex kan man låse disse sectioner af så andre processer/tråde ikke kan tilgå samme section, når processen med låsen er færdig i den section vil mutex frigive låsen og lade andre processer/tråde tilgå den kritiske section. 

[Comment: indsæt citatet fra hjemmesiden.]

## Semaphores
Semaphores er en anden variation til at låse kritiske sectioner af med, de følger dog et andet princip de har en variabel med sig som betegner hvor mange pladser der er til processer/tråde kan køre simultant med hinanden. Når alle pladser er i brug vil semaphoren blocke adgangen til sectionen, og først give adgang når der er plads igen. Følgende kan forståes ved semaphorens metoder: wait og post Hvad de gør har en virkning på den variable som semaphoren har med sig, wait vil sænke variablen med 1 -- reducere antallet a ledige pladser, og post vil hæve variablen med 1 -- øge antallet af ledige pladser. Når variablen når 0 vil wait vente på et post.

[Comment: indsæt citatet fra hjemmesiden.]

## Pthread_cond vs semaphores
Hvor semaphores blockerer kritiske sectioner. Vil Pthread_cond blockere på værdier den har brug for andet steds fra hvis man har 2 tråde hvor at tråd A gør brug af en global variable X som tråd B ændre kan man i tråd A vente på en at B har ændret præcis denne variable x. så foreskellen mellem pthread_cond og semaphore er at pthread_cond blocker på værdier fremfor sectioner, og derved kun blockere når det er højst nødvendigt for hvis tråd B er færdig før A så vil den bare fortsætte fordi variablen allerede er blevet ændret.


## Concurenxy Control:
Når man har noget data som mange skal bruge på samme tid hvordan opnås dette sådan at de ændringer som bliver lavet ikke er forkerte når andre skal bruge dem? det er hvad concurrency control er. De tiltag man tager sådan at ens data er konsistent og korrekt. I concurency control har man transaktioner som er processer som udfører nogle handlinger der generelt betegnes som læse handlinger og skrive handlinger. Hvis man har to transaktioner som begge har adgang til resscource x, så kan en handling se sådan ud Read(x), Write(x,value). Hvis begge nu skulle lave en Write(x, 34) og Write(x,1000) hvilken skulle så være det der gjaldt dataen er ændret så den næste Process der laver en Read(x) kan ende med to resultater hvilket ikke er godt for at undgå dette skal man sørge for at ens transaktioner er serial eqiuvalent. dette kan gøres på mange måder en af dem er som Mutex hvor man låser den sektion der er data sensitiv af indtil man er sikker på at ændringerne har taget efekt og så er det first come first serve dette gør at man ikke får bad reads det er ikke alt omkring serial equvalence det er at for at de kan være det så kræver det at dataen ser ud efter kørsel af den ene transaktion og så den anden og omvendt og begge giver det samme slut resiultat. 

## Bankers Algorithm:
Er en resource alokerings algoritme som bruger matriser til at allokere ressourcer til processer og holder styr på hvor mange ressourcer af typen R en process har fået. I algoritmen er der 3 matrix´s med størrelsen n*m hvor n er antallet af processer, m er antallet af resource typer R og en vektor Available med længen m som angiver den maksimale mængde resoucer af en given type R der er tilgængelig, Max[nXm] er en matrise som holder styr på hvor mange resourser R en process kan modtage. Need[nXm] er en matrise som angiver algoritmen hvor mange resourcer en given process mangler for de specifikke typer R. Allocated[nXm] er en matrise som håndtere allokeringen af ressourcer på processerne på et givent tidspunkt. Safe state, not safe state er to ord som er en nøglerne til denne algoritme det er dette der afgør om der er nok resourcer til en proces kan udføre sit arbejde og afslutte dette vil være en safe state hvis en process kan acquire alle recsourcer den har brugfor og der er nok til at en anden process kan acquire rescourcer så er det en safe state. Hvis man antager at der er 5 resourcer af typen B og der er tre processer 1, 2, 3. 1 kommer med et request om at den vil have 3 B for at tilfredse den behov så vil bankers algoritme tjekke safe states ved at se om den kan allokere de resourcer hvis ja kigger den på tilstanden efter resourcen er blevet tildelt og ser om der er en proces der stadig kan få tilfredsstillet sit behov for rescourcer. og denne metode gør at man undgår deadlocks fordi der på intet tidspunkt er processer der venter på rescourcer som de aldrig kan få, mindst en process kan altid få nok rescourcer til at afslutte. Denne algoritme har dog nogle downsides som er ret markante, nemlig da man er nød til at vide på forhand hvilke og hvor mange ressourcer en process maksimum skal bruge. Udover dette så at antage at en process skal frigive alle sine resourcer når den terminere hvilket i sigselv er vigtigt for algoritmen da man ikke kan sige levetiden på en given process kan man måske vente dage timer på at de ressourcer tilbage, dette er ikke praktisk for et realistisk system. sådan som vores verden er idag er det ikke logisk at have et statisk antal processore da verden er begyndt at bruge mange flere tråde sombliver oprettet og lukket igen og igen i løbet af et programs levetid. 
\newpage
